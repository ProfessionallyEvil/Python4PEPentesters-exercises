#!/usr/bin/python

# The goal of this exercise is to create a simple command-line utility that will parse a standard apache
# access log and collect statistics to help determine the source(s) of potential malicious activity.
# Collect the following statistics:
#   a) A count of how many times the each IP address is found in the log.
#   b) A list of which distinct IP addresses accessed each resource
# Once this is done, output some useful results by sorting the IP address counts and by listing how many distinct
# IP addresses accessed each resource.
# A sample file is located at ../../files/access.log
#
# IMPORTANT: The log file may be very large, so we want to make sure we do not load the entire file
# into memory at once.

import argparse
import os
import re
import operator

stats_ip = {}   # Dictionary mapping IPs to a count of how many times the same IP shows up
stats_res = {}  # Dictionary mapping resources to a list of distinct IP addresses accessing the resource
pattern_ip = re.compile('^([0-9]{1,3}\.){3}[0-9]{1,3}')     # regex pattern or an IP address
pattern_cmd = re.compile('".*"')    # regex pattern for the entire command (first HTTP line) received.


# This function takes a single log line as input.  It will parse out the IP address and the requested resource
# (URI).  It will return these two items as strings.
def parse_line(line):
    ip_val = None
    res_val = None
    ip = pattern_ip.search(line)
    if ip is not None:
        ip_val = ip.group()
    cmd = pattern_cmd.search(line)
    if cmd is not None:
        cmd_string = cmd.group()
        res_start = cmd_string.find('/')
        res_end = cmd_string.find(' ', res_start+1)
        res_val = cmd_string[res_start:res_end]
    return ip_val, res_val


# This function takes an IP address and resource string as input.  It will then update the two stats dictionaries.
def count_stats(entry_ip, entry_res):
    if entry_ip not in stats_ip:
        stats_ip[entry_ip] = 0
    stats_ip[entry_ip] += 1

    if entry_res not in stats_res:
        stats_res[entry_res] = []
    if entry_ip not in stats_res[entry_res]:
        stats_res[entry_res].append(entry_ip)


# Some test code
# ip, res = parse_line('172.16.103.131 - - [20/Jun/2015:14:03:01 -0400] "GET / HTTP/1.1" 200 13081')
# count_stats(ip, res)

# The main function
if __name__ == "__main__":
    # This arg parser is just set up to take a single parameter, the file to be parsed.
    parser = argparse.ArgumentParser(description='Parse an access log file and generate statistics.')
    parser.add_argument('logfile', help='The file to be parsed.')
    args = parser.parse_args()

    # Read each line of the file and feed it through our parse_line and count_stats functions
    if not os.path.exists(args.logfile):
        print ("Can't find supplied file: %s" % args.logfile)
    else:
        print ("* Reading stats from file...")
        with open(args.logfile, 'r') as f:
            for line in f:
                ip, res = parse_line(line)
                count_stats(ip, res)

    # Print the raw results
    print (stats_ip)
    print (stats_res)

    # Output the IPs in reverse order (largest to smallest access)
    print ("* Sorting IPs...")
    print (sorted(stats_ip.items(), key=operator.itemgetter(1), reverse=True))

    # Output the resources with counts on how many distinct IPs accessed each resource
    print ("* Counting Resource Calls...")
    for resource in stats_res:
        print ('%s: %i' % (resource, len(stats_res[resource])))